apiVersion: v1
data:
  logstash.conf: |-
    input { 
      heartbeat {
        message => "sequence"
        interval => 10
        type => "heartbeat"
      }
      # use the exec plugin to cat the output of the file to the json codec.  This lets us make the entire contents 
      # of the file into a single ES event
      # no sudo in this pod!
      file {
          path => "/data/test.json"
          start_position => "beginning"
          tags => ["fio","test"]
          codec => json
          sincedb_path => "/data/.sincedb"
      }
      exec{
        command => "cat /data/test.json; sudo rm -rf /data/*.*"
        codec => json
        # run command once a minute
        interval => 60
      }
      #file { 
      #  path => "/data/*.log"
      #  start_position => "beginning"
      #} 
    }
    output {
      elasticsearch { 
        hosts => ["elasticsearch:9200"] 
        index => "logstash-fiotest"
      }
      #exec {
      #  command => "sudo /config/cleanup.sh"
      #}
      #stdout { codec => rubydebug }
    }
  logstash.yml: |-
    ## Default Logstash configuration from logstash-docker.
    ## from https://github.com/elastic/logstash-docker/blob/master/build/logstash/config/logstash.yml
    #
    http.host: "0.0.0.0"
    path.config: /usr/share/logstash/pipeline
    #xpack.monitoring.elasticsearch.url: http://elasticsearch:9200
    #xpack.monitoring.elasticsearch.username: logstash_system
    #xpack.monitoring.elasticsearch.password: changeme
    ## Disable X-Pack
    ## see https://www.elastic.co/guide/en/x-pack/current/xpack-settings.html
    ##     https://www.elastic.co/guide/en/x-pack/current/installing-xpack.html#xpack-enabling
    #
    xpack.monitoring.enabled: false
  cleanup.sh: |-
    #!/bin/sh
    rm -rf /data/test.json
    pkill java
kind: ConfigMap
metadata:
  name: logstash-configmap